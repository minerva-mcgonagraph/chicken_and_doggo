{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chicken_and_doggo_fastai_notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minerva-mcgonagraph/chicken_and_doggo/blob/master/chicken_and_doggo_fastai_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-W-vv308Uxo",
        "colab_type": "text"
      },
      "source": [
        "# Labradoodle or Fried Chicken?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtYmh8ZK8Uxr",
        "colab_type": "text"
      },
      "source": [
        "![eight alternating pictures of similar-looking labradoodles and fried chicken](https://media.npr.org/assets/img/2016/03/11/labradoodle-or-fried-chicken_wide-14bb65d1f6416afcc4bdf20fbf1d4d6cbe381a5a.jpg?s=1400)\n",
        "\n",
        "You've seen the meme. Now get ready for the AI that can tell the difference.\n",
        "\n",
        "This notebook builds an artificial intelligence model that classifies an image as either a labradoodle (doggo) or fried chicken.\n",
        "\n",
        "Hover over the \\[  ] in each code block and click the little play button to run it.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW16p9fG-CnV",
        "colab_type": "text"
      },
      "source": [
        "First, we need to get the data set. I scraped some images off of Google and placed them neatly in a dropbox. Run the following code to grab them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvQMmmE-6aQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://www.dropbox.com/s/4q6coicseieqinh/chicken_and_doggo_dataset.zip?dl=0 \\\n",
        "    -O /tmp/chicken_and_doggo_dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsbeqioO-iAs",
        "colab_type": "text"
      },
      "source": [
        "Next we need to initialize a few things, import some libraries, and unzip the box of dogs and chicken. (Pause to consider those words out of context.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb2rQeB78Uxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate\n",
        "\n",
        "local_zip = '/tmp/chicken_and_doggo_dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvnKeVm18Uxx",
        "colab_type": "text"
      },
      "source": [
        "Now we'll set the batch size and image size. The batch size is the number of examples used in each training iteration. The image size will be used to transform each image into a square of that many pixels on each side.\n",
        "\n",
        "Geek out: The images in the data set are all different sizes. In convolutional neural networks with fully connected layers, like what's used here, the images must be transformed into the same size. This makes the model much faster but also means that images can get cropped and stretched and distorted. If you have nice, polite images where each image contains either a dog or some fried chicken it's not an issue. But tasks that involve object detection require a different approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxPFVZy58Uxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "image_size = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh9BG1r68Ux8",
        "colab_type": "text"
      },
      "source": [
        "Now we'll retrieve the image classes.\n",
        "\n",
        "This can be done manually since there are only 2 classes (doggo and chicken), but this code can scale to much larger data sets.\n",
        "\n",
        "First we say where all the images are by defining PATH. Then we create a blank list of classes, and for each folder in the directory, add the name of the folder to the list, ignoring folders we don't want. Then we'll print the class names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm5J7HIs8Ux9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/tmp/chicken_and_doggo_dataset'\n",
        "\n",
        "classes = []\n",
        "for d in os.listdir(PATH):\n",
        "    if os.path.isdir(os.path.join(PATH, d)) and not d.startswith('.') and not d=='models':\n",
        "        classes.append(d)\n",
        "print(\"There are\", len(classes), \"classes:\\n\", classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XgvFnco8UyD",
        "colab_type": "text"
      },
      "source": [
        "Time to start the fun stuff. In this next cell we'll create the training and validation sets using some handy functions from the fastai library. Notice the image_size and batch_size from earlier!\n",
        "\n",
        "We'll also look at the data, just to make sure it's what we want. If you run the cell over again, you will see different images. So if you want to be really sure the data is good and totally not just have an excuse to look at cute pictures of labradoodles and fried chicken, run the code as many times as you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijREnphO8UyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = ImageDataBunch.from_folder(\n",
        "    PATH, \n",
        "    ds_tfms=get_transforms(),\n",
        "    size=image_size,\n",
        "    bs=batch_size,\n",
        "    valid_pct=0.2).normalize(imagenet_stats)\n",
        "print(\"There are\", len(data.train_ds), \"training images and\",\n",
        "    len(data.valid_ds), \"validation images.\")\n",
        "data.show_batch(rows=3, figsize=(7,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djo6jpOV8UyM",
        "colab_type": "text"
      },
      "source": [
        "And now we start the fancy stuff. The convolutional neural network (CNN) we're using here is resnet34. Residual Neural Networks were created by Kaiming He et al and won the ILSVRC in 2015, which is AI jargon for \"they're really good.\" And thanks to the fastai library, we can build them with only a couple lines of code.\n",
        "\n",
        "How ResNets and other CNNs work is a bit beyond the scope of this documentation. To give you a very general idea of how they work, a model is trained by taking a batch of images, extracting features and finding a best fit curve for how those features weigh in on determining the image class. This is repeated for a certain number of iterations (epochs) and the model adjusts the best fit curve. The amount of adjustment is based on a learning rate.\n",
        "\n",
        "In this ResNet, the following code will run mock trainings using different learning rates. The final plot shown shows the loss at different learning rates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffIFVP8K8UyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = cnn_learner(data, models.resnet34, metrics=accuracy)\n",
        "learn.lr_find();\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2mSmIrG8UyU",
        "colab_type": "text"
      },
      "source": [
        "Now we'll pick two learning rates: 0.01 and 0.001 (in the graph, these are labeled as 1e-02 and 1e-03 respectively). There's reasons for picking these two but that's beyond the scope of this documentation. Then train the model, cycling between these two learning rates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peojDbAo8UyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(4, max_lr=slice(1e-3,1e-2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzXGVRF08Uya",
        "colab_type": "text"
      },
      "source": [
        "So what are we looking at? Where are the pictures of labradoodles and fried chicken?\n",
        "\n",
        "Well, the table shows the accuracy of the model. It's a probability in the form of a decimal, so an accuracy in the final epoch of 0.98 means the model can accurately determine if the image is of a labradoodle or fried chicken correctly 98% of the time. The accuracy numbers you get may be slightly different (if they look weird, just run it again) due to the randomness of training.\n",
        "\n",
        "But we just built a high accuracy classification model with only a few lines of code! And for those who know a little about data science, we did this without any effort in tuning parameters!\n",
        "\n",
        "One last thing! Run the following code to free up memory (it will say it has crashed and is restarting). Then enjoy some more pictures of labradoodles and fried chicken."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYrZeA5a_gd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5V1ZJlALtaF",
        "colab_type": "text"
      },
      "source": [
        "![eight more alternating images of similar-looking labradoodles and fried chicken](https://www.dropbox.com/s/tphoccpoqa33wmq/doggochicken2.jpg?dl=0)"
      ]
    }
  ]
}