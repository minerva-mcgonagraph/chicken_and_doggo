{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chicken_and_doggo_fastai_notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minerva-mcgonagraph/chicken_and_doggo/blob/master/chicken_and_doggo_fastai_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-W-vv308Uxo",
        "colab_type": "text"
      },
      "source": [
        "# CNN that distinguishes between a picture of a labradoodle and fried chicken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtYmh8ZK8Uxr",
        "colab_type": "text"
      },
      "source": [
        "initialization and importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvQMmmE-6aQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://www.dropbox.com/s/4q6coicseieqinh/chicken_and_doggo_dataset.zip?dl=0 \\\n",
        "    -O /tmp/chicken_and_doggo_dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb2rQeB78Uxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate\n",
        "\n",
        "local_zip = '/tmp/chicken_and_doggo_dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvnKeVm18Uxx",
        "colab_type": "text"
      },
      "source": [
        "Set batch size and image size - this is the size that images will be transformed to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxPFVZy58Uxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "image_size = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNxZGPzZ8Ux2",
        "colab_type": "text"
      },
      "source": [
        "Set base path. This is where the data is located."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ612s_J8Ux4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/tmp/chicken_and_doggo_dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh9BG1r68Ux8",
        "colab_type": "text"
      },
      "source": [
        "Code to retrieve the image classes. For a small set of classes like the ones here this would be easier to do manually, but using this code scales to much larger class sets.\n",
        "\n",
        "This is done by first initializing a blank list, then running through all folders in the base directory while ignoring hidden folders (those that begin with a period). For each folder it finds, that name is added to the list. This also skips the 'models' folder, since that's not a class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm5J7HIs8Ux9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = []\n",
        "for d in os.listdir(PATH):\n",
        "    if os.path.isdir(os.path.join(PATH, d)) and not d.startswith('.') and not d=='models':\n",
        "        classes.append(d)\n",
        "print(\"There are\", len(classes), \"classes:\\n\", classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XgvFnco8UyD",
        "colab_type": "text"
      },
      "source": [
        "Make a function to create training and validation sets. This takes advantage of the fastai library to split the data. We'll also visualize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijREnphO8UyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = ImageDataBunch.from_folder(\n",
        "    PATH, \n",
        "    ds_tfms=get_transforms(),\n",
        "    size=image_size,\n",
        "    bs=batch_size,\n",
        "    valid_pct=0.2).normalize(imagenet_stats)\n",
        "print(\"There are\", len(data.train_ds), \"training images and\",\n",
        "    len(data.valid_ds), \"validation images.\")\n",
        "data.show_batch(rows=3, figsize=(7,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djo6jpOV8UyM",
        "colab_type": "text"
      },
      "source": [
        "Now we'll build the CNN using resnet34. We can build an entire CNN using just a couple lines of code through the fastai library. The following will run mock trainings using different learning rates. Next we'll pick two learning rates to cycle between for the actual training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffIFVP8K8UyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = cnn_learner(data, models.resnet34, metrics=accuracy)\n",
        "learn.lr_find();\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2mSmIrG8UyU",
        "colab_type": "text"
      },
      "source": [
        "Pick two learning rates: 0.01 and 0.001 (in the graph, these are labeled as 1e-02 and 1e-03 respectively). There's reasons for picking these two but that's beyond the scope of this documentation (for now). Retrain based on these learning rates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peojDbAo8UyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(4, max_lr=slice(1e-3,1e-2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzXGVRF08Uya",
        "colab_type": "text"
      },
      "source": [
        "That's it! A high accuracy classification model that doesn't require a lot of effort in tuning parameters. :) Don't forget to run the following to free up memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYrZeA5a_gd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}